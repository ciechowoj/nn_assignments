{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [Fuel](https://github.com/mila-udem/fuel) library to access datasets. Fuel is designed to provide easy iteration over large datasets, however in this assignment we will only use its ability to download and convert some standard datasets for us.\n",
    "\n",
    "We will use the following datasets:\n",
    "1. IRIS https://archive.ics.uci.edu/ml/datasets/Iris available as `fuel.datasets.iris.Iris`\n",
    "2. MNIST http://yann.lecun.com/exdb/mnist/ available as `fuel.datasets.mnist.MNIST`\n",
    "3. CIFAR10 http://www.cs.toronto.edu/~kriz/cifar.html available as `fuel.datasets.cifar10.CIFAR10`\n",
    "\n",
    "On lab computers the datasets have already been downloaded for you into the `/pio/data/data/fuel` directory. Make sure to add it to the `FUEL_DATA_PATH` environment variable!\n",
    "\n",
    "If you are working from your computer, you can either use the Fuel downloader and converter utulities (http://fuel.readthedocs.org/en/latest/built_in_datasets.html) or download the HDF5 datasets:\n",
    "\n",
    "1. [Iris](https://drive.google.com/uc?export=download&id=0B5j9vIO_Njwcb2ItV2ZLakR6MEk)\n",
    "2. [MNIST](https://drive.google.com/uc?export=download&id=0B5j9vIO_NjwcNnYzVTNIVGxaSEk)\n",
    "3. [CIFAR10](https://drive.google.com/uc?export=download&id=0B5j9vIO_NjwcOEdlU2RtNkc2bW8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50000 training, 10000 validation, and 10000 test examples\n",
      "The examples are pairs of ('features', 'targets'):\n",
      "The source #0 named \"features\" is a 4 array with axis: ('batch', 'channel', 'height', 'width')\n",
      "The source #1 named \"targets\" is a 2 array with axis: ('batch', 'index')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAD/CAYAAACO0nHRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f688875b9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading MNIST data\n",
    "\n",
    "from fuel.datasets.mnist import MNIST\n",
    "from common.plotting import plot_mat\n",
    "\n",
    "mnist_train = MNIST((\"train\",), subset=slice(None,50000))\n",
    "mnist_validation = MNIST((\"train\",), subset=slice(50000, None))\n",
    "mnist_test = MNIST((\"test\",))\n",
    "\n",
    "print(\"We have {} training, {} validation, and {} test examples\".format(\n",
    "    mnist_train.num_examples, mnist_validation.num_examples, mnist_test.num_examples))\n",
    "      \n",
    "print(\"The examples are pairs of {}:\".format(mnist_train.sources))\n",
    "\n",
    "for i, source in enumerate(mnist_train.sources):\n",
    "    labels = mnist_train.axis_labels[source]\n",
    "    print('The source #{} named \"{}\" is a {} array with axis: {}'.format(\n",
    "        i, source, len(labels), labels))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#Note that for larger datasets that are loaded into mameory the data_sources field may not exist!\n",
    "plot_mat(mnist_train.data_sources[0][:20], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: plot an example of each class on MNIST and on CIFAR\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract the data matrices\n",
    "\n",
    "mnist_train_X = (mnist_train.data_sources[0].reshape(mnist_train.num_examples, -1) / 255.0).astype(np.single)\n",
    "mnist_train_Y = mnist_train.data_sources[1].ravel()\n",
    "\n",
    "mnist_valid_X = (mnist_validation.data_sources[0].reshape(mnist_validation.num_examples, -1) / 255.0).astype(np.single)\n",
    "mnist_valid_Y = mnist_validation.data_sources[1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def KNN(train_X, train_Y, test_X, test_Y, ks, batch_size=200):\n",
    "    \"\"\"\n",
    "    Compute error rate for various \n",
    "    \"\"\"\n",
    "    errs = np.zeros((len(ks),))\n",
    "    for i in xrange(0,test_Y.shape[0], batch_size):\n",
    "        batch_X = test_X[i:i + batch_size]\n",
    "        batch_Y = test_Y[i:i + batch_size]\n",
    "        print \"Examples %d:%d Computing distances... \" %(i,i+batch_size), \n",
    "        \n",
    "        #\n",
    "        # TODO: fill in an efficient distance matrix computation \n",
    "        #\n",
    "        dists = TODO\n",
    "        \n",
    "        print \"Sorting... \",\n",
    "        closest = np.argsort(dists,0)\n",
    "\n",
    "        print \"Computing errors...\"\n",
    "        targets = train_Y[closest]\n",
    "        \n",
    "        for ki,k in enumerate(ks):\n",
    "            predictions, unused_counts = mode(targets[:k,:], axis=0)\n",
    "            predictions = predictions.ravel()\n",
    "            #\n",
    "            # TODO: fill in error count computation\n",
    "            #\n",
    "            errs[ki] += TODO\n",
    "        \n",
    "    errs /= test_Y.shape    \n",
    "    return np.vstack((ks, errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now find the best k on the validation set\n",
    "\n",
    "mnist_validation_errs = KNN(mnist_train_X, mnist_train_Y, mnist_valid_X, mnist_valid_Y, [1,3,5,7,9])\n",
    "plot(mnist_validation_errs[0,:], mnist_validation_errs[1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now use the best k to compute the test error\n",
    "\n",
    "best_K =  TODO\n",
    "\n",
    "mnist_full_train = MNIST((\"train\",), )\n",
    "\n",
    "mnist_full_train_X = (mnist_full_train.data_sources[0].reshape(mnist_full_train.num_examples, -1) / 255.0).astype(np.single)\n",
    "mnist_full_train_Y = mnist_full_train.data_sources[1].ravel()\n",
    "\n",
    "mnist_test_X = (mnist_test.data_sources[0].reshape(mnist_test.num_examples, -1) / 255.0).astype(np.single)\n",
    "mnist_test_Y = mnist_test.data_sources[1].ravel()\n",
    "\n",
    "mnist_test_errs = KNN(mnist_full_train_X, mnist_full_train_Y, mnist_test_X, mnist_test_Y, [best_K])\n",
    "print \"When k=%d the test error rate is %.1f%%\" % (mnist_test_errs[0,0], mnist_test_errs[1,0]*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Now repeat the k-NN training for CIFAR10\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Solve problem 2 here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.gradients import check_gradient,numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A sample function for debugging purposes\n",
    "\n",
    "def quadratic(X):\n",
    "    value = X[0]**2 + 2*X[1]**2\n",
    "    grad = np.array([2*X[0], 2*X[1]]) # TODO\n",
    "    return (value, grad)\n",
    "\n",
    "\n",
    "# Let's check if the gradientis correctly computed\n",
    "check_gradient(quadratic, np.array([0,0]))\n",
    "check_gradient(quadratic, np.array([1.0,1.0]))\n",
    "\n",
    "# Oh noes! We have an error in gradient computation - please correct it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Fill in the details of the gradient computation\n",
    "#\n",
    "\n",
    "def GD(f, Theta0, alpha, stop_tolerance=1e-10, max_steps=1000000):\n",
    "    history = [Theta0]\n",
    "    \n",
    "    Theta = Theta0\n",
    "    value = np.inf\n",
    "    \n",
    "    step = 0\n",
    "    while step<max_steps:\n",
    "        previous_value = value\n",
    "        value, gradient = f(Theta)\n",
    "        if TODO: #fill in a stopping condition here\n",
    "            break\n",
    "        \n",
    "        Theta = TODO #fill in the gradient descent rule\n",
    "        history.append(Theta)\n",
    "        step += 1\n",
    "    return Theta, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Test the GD procedure on the quadratic function\n",
    "#\n",
    "\n",
    "Xopt, Xhist = GD(quadratic, np.array((1,1)), 1e-1)\n",
    "print \"Found optimum at %s in %d steps (true minimum is at [0,0])\" % (Xopt, len(Xhist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Now implement the Rosenbrock function \n",
    "#\n",
    "\n",
    "def rosenbrock(x):\n",
    "    val = TODO\n",
    "    grad = TODO\n",
    "    return val, grad\n",
    "\n",
    "#\n",
    "# And test its gradient\n",
    "#\n",
    "check_gradient(rosenbrock, np.array([0.,0.]), delta=1e-8)\n",
    "check_gradient(rosenbrock, np.array([1.0,1.0]), delta=1e-8)\n",
    "\n",
    "#\n",
    "# Find the optimum\n",
    "#\n",
    "\n",
    "X0= (0.,2.)\n",
    "Xopt, Xhist = GD(rosenbrock, X0, alpha=TODO, stop_tolerance=1e-10)\n",
    "Xhist = np.array(Xhist)\n",
    "\n",
    "print \"Found optimum at %s in %d steps (true minimum is at [1,1])\" % (Xopt, len(Xhist))\n",
    "\n",
    "#\n",
    "# Plot the value over iterations\n",
    "#\n",
    "\n",
    "#TODO\n",
    "\n",
    "#\n",
    "# Make a contour plot\n",
    "#\n",
    "# you may want to use functions: meshgrid, contour\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Use scipy.optimize.fmin_l_bfgs_b\n",
    "# Again plot the path on the coutnour plot\n",
    "#\n",
    "# Hint: to save the points you can use the callback argument!\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print 'Features: ', iris.feature_names\n",
    "print 'Targets: ', iris.target_names\n",
    "petal_length = iris.data[:,iris.feature_names.index('petal length (cm)')]\n",
    "petal_width = iris.data[:, iris.feature_names.index('petal width (cm)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract the petal_length and petal_width of versicolors and virginicas\n",
    "\n",
    "IrisX = np.vstack([np.ones_like(petal_length), petal_length, petal_width])\n",
    "IrisX = IrisX[:, iris.target!=0]\n",
    "\n",
    "# Set versicolor=0 and virginia=1\n",
    "IrisY = (iris.target[iris.target!=0]-1).reshape(1,-1).astype(np.float64)\n",
    "\n",
    "scatter(IrisX[1,:], IrisX[2,:], c=IrisY.ravel(), cmap='spring')\n",
    "xlabel('petal_length')\n",
    "ylabel('petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionCost(object):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "    #note: this creates a Pyton callable - i.e. an abject that can be called as a function\n",
    "    def __call__(self, Theta):\n",
    "        X = self.X\n",
    "        Y = self.Y\n",
    "        \n",
    "        #reshape Theta\n",
    "        ThetaR = Theta.reshape(X.shape[0],1)\n",
    "        \n",
    "        #\n",
    "        # Fill in negative log likelihood computation\n",
    "        # and gradient computation\n",
    "        #\n",
    "        # Properly implemented, this takes about 3 lines of code!\n",
    "        #\n",
    "        \n",
    "        nll = TODO\n",
    "        \n",
    "        grad = TODO\n",
    "        \n",
    "        #reshape gard into the shape of Theta, for fmin_l_bfsgb to work\n",
    "        return nll, grad.reshape(Theta.shape)\n",
    "\n",
    "iris_log_reg = LogisticRegressionCost(IrisX, IrisY)\n",
    "\n",
    "Theta0 = np.zeros((3))\n",
    "check_gradient(iris_log_reg, Theta0)\n",
    "\n",
    "#\n",
    "# Maybe check the gradients at a few other points too?\n",
    "#\n",
    "\n",
    "\n",
    "#\n",
    "# Call a solver\n",
    "#\n",
    "\n",
    "ThetaOpt = GD(iris_log_reg, Theta0, alpha=TODO)[0]\n",
    "\n",
    "#\n",
    "# TODO: also tru f_min_lbfsgb??\n",
    "#\n",
    "\n",
    "check_gradient(iris_log_reg, ThetaOpt)\n",
    "\n",
    "\n",
    "#\n",
    "# Now plot the found separation line \n",
    "# \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
